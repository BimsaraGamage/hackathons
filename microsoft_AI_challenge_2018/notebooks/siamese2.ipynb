{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.layers import TimeDistributed, Lambda\n",
    "from keras.layers import Convolution1D, GlobalMaxPooling1D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.preprocessing import sequence, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 15393703127507441911, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 11021298170085022729\n",
       " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 3132006109820702862\n",
       " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 15597548340\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 6994167729943694577\n",
       " physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib ; device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_text</th>\n",
       "      <th>passage_text</th>\n",
       "      <th>label</th>\n",
       "      <th>passage_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>.  what is a corporation ?</td>\n",
       "      <td>a company is incorporated in a specific nation...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>.  what is a corporation ?</td>\n",
       "      <td>today ,  there is a growing community of more ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>.  what is a corporation ?</td>\n",
       "      <td>corporation ddefinition ,  an association of i...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>.  what is a corporation ?</td>\n",
       "      <td>examples of corporation in a sentence .  1  he...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>.  what is a corporation ?</td>\n",
       "      <td>1 :  a government  -  owned corporation  ( as ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                    query_text  \\\n",
       "0         0   .  what is a corporation ?    \n",
       "1         0   .  what is a corporation ?    \n",
       "2         0   .  what is a corporation ?    \n",
       "3         0   .  what is a corporation ?    \n",
       "4         0   .  what is a corporation ?    \n",
       "\n",
       "                                        passage_text  label  passage_id  \n",
       "0  a company is incorporated in a specific nation...      0           0  \n",
       "1  today ,  there is a growing community of more ...      0           1  \n",
       "2  corporation ddefinition ,  an association of i...      0           2  \n",
       "3  examples of corporation in a sentence .  1  he...      0           3  \n",
       "4  1 :  a government  -  owned corporation  ( as ...      0           4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/data_p.tsv', sep='\\t')\n",
    "# data = pd.read_csv('../data/data_p.tsv', sep='\\t', names=['query_id', 'query_text', 'passage_text', 'label', 'passage_id'])\n",
    "\n",
    "data['label'] = pd.to_numeric(data['label'])\n",
    "data.head(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 4717692, 1: 524188})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.label.values\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling to reduce data for balancing and handling OOM error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_text</th>\n",
       "      <th>passage_text</th>\n",
       "      <th>label</th>\n",
       "      <th>passage_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1517028</th>\n",
       "      <td>124131</td>\n",
       "      <td>how much vacation time do boeing employees get</td>\n",
       "      <td>online and mobile banking will be unavailable ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213916</th>\n",
       "      <td>750068</td>\n",
       "      <td>cost of laminate flooring for bathrooms</td>\n",
       "      <td>durable laminate flooring is a low  -  cost op...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4414644</th>\n",
       "      <td>414673</td>\n",
       "      <td>what tv show is captain john on</td>\n",
       "      <td>also pictured are actors alan alda and loretta...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187126</th>\n",
       "      <td>38148</td>\n",
       "      <td>define burn candle both ends</td>\n",
       "      <td>burning the candle at both ends   -   meaning ...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171654</th>\n",
       "      <td>734968</td>\n",
       "      <td>what time does ebenefits update</td>\n",
       "      <td>we greatly appreciate the veterans and other e...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         query_id                                      query_text  \\\n",
       "1517028    124131  how much vacation time do boeing employees get   \n",
       "1213916    750068         cost of laminate flooring for bathrooms   \n",
       "4414644    414673                 what tv show is captain john on   \n",
       "187126      38148                    define burn candle both ends   \n",
       "1171654    734968                 what time does ebenefits update   \n",
       "\n",
       "                                              passage_text  label  passage_id  \n",
       "1517028  online and mobile banking will be unavailable ...      0           7  \n",
       "1213916  durable laminate flooring is a low  -  cost op...      0           8  \n",
       "4414644  also pictured are actors alan alda and loretta...      1           3  \n",
       "187126   burning the candle at both ends   -   meaning ...      1           6  \n",
       "1171654  we greatly appreciate the veterans and other e...      0           7  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frac_for_0 = 3/9\n",
    "result1 = data[data.label==1]\n",
    "result0 = data[data.label==0].sample(frac=frac_for_0) \n",
    "data = pd.concat([result1, result0], axis=0).sample(frac=1) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1572564, 1: 524188})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.label.values\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096752, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk = text.Tokenizer(num_words=840000000000)\n",
    "\n",
    "max_len_q = 12\n",
    "max_len_p = 20\n",
    "tk.fit_on_texts(list(data.query_text.values.astype(str)) + list(data.passage_text.values.astype(str)))\n",
    "\n",
    "x1 = tk.texts_to_sequences(data.query_text.values.astype(str))\n",
    "x1 = sequence.pad_sequences(x1, maxlen=max_len_q)\n",
    "\n",
    "x2 = tk.texts_to_sequences(data.passage_text.values.astype(str))\n",
    "x2 = sequence.pad_sequences(x2, maxlen=max_len_p)\n",
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tk, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,    29,    85,  3351,    55,    43,\n",
       "       10979,   891,    93], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  203,  1658,   275,   500,    39,   203,   399,  2009,  1568,\n",
       "           8,  4288,  2095,    86, 26544,     8,   102, 20360,    28,\n",
       "          49,   128], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196017it [02:44, 13318.67it/s]\n"
     ]
    }
   ],
   "source": [
    "word_index = tk.word_index\n",
    "\n",
    "# ytrain_enc = np_utils.to_categorical(y)\n",
    "\n",
    "emb_size = 300 #100\n",
    "file_path = '../glove.840B/glove.840B.%sd.txt'%emb_size\n",
    "# file_path = '../glove.6B/glove.6B.%sd.txt'%emb_size\n",
    "\n",
    "def load_embed(file):\n",
    "    def get_coefs(word,*arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "    \n",
    "    if file.split('.')[-1] == 'vec':\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in tqdm(open(file, encoding='utf-8')) if len(o)>100)\n",
    "    else:\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in tqdm(open(file, encoding='latin')))\n",
    "        \n",
    "    return embeddings_index\n",
    "\n",
    "embeddings_index = load_embed(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 54250/677173 [00:00<00:02, 260647.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2196016 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 677173/677173 [00:01<00:00, 457173.20it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, emb_size))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "max_features = 200000\n",
    "filter_length = 5\n",
    "nb_filter = 64\n",
    "pool_length = 4\n",
    "\n",
    "model = Sequential()\n",
    "print('Build model...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:76: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:77: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(300, dropout=0.2, recurrent_dropout=0.2)`\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:80: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:81: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(300, dropout=0.2, recurrent_dropout=0.2)`\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Embedding(len(word_index) + 1,\n",
    "                     emb_size,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len_q,\n",
    "                     trainable=False))\n",
    "\n",
    "model1.add(TimeDistributed(Dense(emb_size, activation='relu')))\n",
    "model1.add(Lambda(lambda x: K.sum(x, axis=1), output_shape=(emb_size,)))\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(len(word_index) + 1,\n",
    "                     emb_size,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len_p,\n",
    "                     trainable=False))\n",
    "\n",
    "model2.add(TimeDistributed(Dense(emb_size, activation='relu')))\n",
    "model2.add(Lambda(lambda x: K.sum(x, axis=1), output_shape=(emb_size,)))\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(len(word_index) + 1,\n",
    "                     emb_size,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len_q,\n",
    "                     trainable=False))\n",
    "model3.add(Conv1D(filters=nb_filter,\n",
    "                         kernel_size=filter_length,\n",
    "                         padding='valid',\n",
    "                         activation='relu',\n",
    "                         strides=1))\n",
    "model3.add(Dropout(0.2))\n",
    "\n",
    "model3.add(Conv1D(filters=nb_filter,\n",
    "                         kernel_size=filter_length,\n",
    "                         padding='valid',\n",
    "                         activation='relu',\n",
    "                         strides=1))\n",
    "\n",
    "model3.add(GlobalMaxPooling1D())\n",
    "model3.add(Dropout(0.2))\n",
    "\n",
    "model3.add(Dense(emb_size))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(BatchNormalization())\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(Embedding(len(word_index) + 1,\n",
    "                     emb_size,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len_p,\n",
    "                     trainable=False))\n",
    "model4.add(Conv1D(filters=nb_filter,\n",
    "                         kernel_size=filter_length,\n",
    "                         padding='valid',\n",
    "                         activation='relu',\n",
    "                         strides=1))\n",
    "model4.add(Dropout(0.2))\n",
    "\n",
    "model4.add(Conv1D(filters=nb_filter,\n",
    "                         kernel_size=filter_length,\n",
    "                         padding='valid',\n",
    "                         activation='relu',\n",
    "                         strides=1))\n",
    "\n",
    "model4.add(GlobalMaxPooling1D())\n",
    "model4.add(Dropout(0.2))\n",
    "\n",
    "model4.add(Dense(emb_size))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(BatchNormalization())\n",
    "\n",
    "blstm_merge_mode = 'ave' #'concat'\n",
    "\n",
    "model5 = Sequential()\n",
    "model5.add(Embedding(len(word_index) + 1, emb_size, input_length=max_len_q, dropout=0.2))\n",
    "model5.add(Bidirectional(LSTM(emb_size, dropout_W=0.2, dropout_U=0.2), merge_mode=blstm_merge_mode))\n",
    "\n",
    "model6 = Sequential()\n",
    "model6.add(Embedding(len(word_index) + 1, emb_size, input_length=max_len_p, dropout=0.2))\n",
    "model6.add(Bidirectional(LSTM(emb_size, dropout_W=0.2, dropout_U=0.2), merge_mode=blstm_merge_mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submodel_inputs = [model.input for model in [model1, model2, model3, model4, model5, model6]]\n",
    "# submodel_outputs = [model.output for model in [model1, model2, model3, model4, model5, model6]]\n",
    "# # https://stackoverflow.com/questions/45979848/merge-2-sequential-models-in-keras\n",
    "# mergedout = Concatenate(axis=1)(submodel_outputs)\n",
    "\n",
    "# mergedout = BatchNormalization()(mergedout)\n",
    "\n",
    "# mergedout = Dense(emb_size)(mergedout)\n",
    "# mergedout = PReLU()(mergedout)\n",
    "# mergedout = Dropout(0.2)(mergedout)\n",
    "# mergedout = BatchNormalization()(mergedout)\n",
    "\n",
    "# mergedout = Dense(emb_size)(mergedout)\n",
    "# mergedout = PReLU()(mergedout)\n",
    "# mergedout = Dropout(0.2)(mergedout)\n",
    "# mergedout = BatchNormalization()(mergedout)\n",
    "\n",
    "# mergedout = Dense(1)(mergedout)\n",
    "# mergedout = Activation('sigmoid')(mergedout)\n",
    "\n",
    "# checkpoint = ModelCheckpoint('../data/siamese.{epoch:02d}-{val_acc:.2f}.hdf5', monitor='val_acc', save_best_only=False, verbose=2)\n",
    "# newModel = Model(submodel_inputs, mergedout)\n",
    "# newModel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"lambda_1/Sum:0\", shape=(?, 300), dtype=float32)\n",
      "Tensor(\"lambda_2/Sum:0\", shape=(?, 300), dtype=float32)\n",
      "Tensor(\"batch_normalization_1/cond/Merge:0\", shape=(?, 300), dtype=float32)\n",
      "Tensor(\"batch_normalization_2/cond/Merge:0\", shape=(?, 300), dtype=float32)\n",
      "Tensor(\"bidirectional_1/truediv:0\", shape=(?, 300), dtype=float32)\n",
      "Tensor(\"bidirectional_2/truediv:0\", shape=(?, 300), dtype=float32)\n",
      "(?, 300)\n",
      "(?, 300)\n",
      "(?, 300)\n"
     ]
    }
   ],
   "source": [
    "submodel_inputs = [model.input for model in [model1, model2, model3, model4, model5, model6]]\n",
    "[print(model.output) for model in [model1, model2, model3, model4, model5, model6]]\n",
    "submodel_outputs = [model.output for model in [model1, model2, model3, model4, model5, model6]]\n",
    "\n",
    "# https://stackoverflow.com/questions/45979848/merge-2-sequential-models-in-keras\n",
    "# mergedout = Concatenate(axis=1)(submodel_outputs)\n",
    "mergedout1 = Average()([model1.output, model3.output, model5.output])\n",
    "mergedout2 = Average()([model2.output, model4.output, model6.output])\n",
    "mergedout = Multiply()([mergedout1, mergedout2])\n",
    "\n",
    "print(mergedout1.shape)\n",
    "print(mergedout2.shape)\n",
    "print(mergedout.shape)\n",
    "\n",
    "mergedout = BatchNormalization()(mergedout)\n",
    "\n",
    "mergedout = Dense(emb_size)(mergedout)\n",
    "mergedout = PReLU()(mergedout)\n",
    "mergedout = Dropout(0.2)(mergedout)\n",
    "mergedout = BatchNormalization()(mergedout)\n",
    "\n",
    "mergedout = Dense(1)(mergedout)\n",
    "mergedout = Activation('sigmoid')(mergedout)\n",
    "\n",
    "checkpoint = ModelCheckpoint('../data/siamese.{epoch:02d}-{val_acc:.2f}.hdf5', monitor='val_acc', save_best_only=False, verbose=2)\n",
    "newModel = Model(submodel_inputs, mergedout)\n",
    "newModel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:          61406       12259       25054        2062       24092       46506\r\n",
      "Swap:             0           0           0\r\n"
     ]
    }
   ],
   "source": [
    "!free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0, 1: 3.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = {0: 1., 1: float(1/frac_for_0)}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newModel.fit(x=[x1, x2, x1, x2, x1, x2], y=y, batch_size=512, epochs=5, \n",
    "             verbose=1, validation_split=0.1, shuffle=True, \n",
    "             class_weight=class_weights, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.enable_eager_execution()\n",
    "\n",
    "# a = tf.convert_to_tensor(\n",
    "#     [[1,2], [3,4]],\n",
    "#     dtype=None,\n",
    "#     name=None,\n",
    "#     preferred_dtype=None\n",
    "# )\n",
    "\n",
    "# b = tf.convert_to_tensor(\n",
    "#     [[1,2], [3,4]],\n",
    "#     dtype=None,\n",
    "#     name=None,\n",
    "#     preferred_dtype=None\n",
    "# )\n",
    "\n",
    "# Dot(axes=1)([a,b])\n",
    "# Multiply()([a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
